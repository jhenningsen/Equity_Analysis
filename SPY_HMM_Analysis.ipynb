{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "SPY_HMM_Analysis.ipynb",
      "authorship_tag": "ABX9TyOuoWGEHPOLVcZ7beTjCp6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhenningsen/Equity_Analysis/blob/main/SPY_HMM_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x0-T4zad9-2",
        "outputId": "398c3f05-39d5-420b-d512-ecf33b087664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from hmmlearn import hmm\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "OVwj6PYfmrCQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPY Only\n"
      ],
      "metadata": {
        "id": "0J5q6gnRo27s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# Tickers\n",
        "TICKERS = ['SPY']\n",
        "# Date Range (Adjust as needed)\n",
        "START_DATE = '2022-01-01'\n",
        "END_DATE = '2025-10-25'\n",
        "# HMM Parameters\n",
        "N_COMPONENTS = 3 # Number of hidden states (regimes)\n",
        "\n",
        "# 1. Download Data\n",
        "# Download the data and select the 'Close' price.\n",
        "data_series = yf.download(TICKERS, start=START_DATE, end=END_DATE)['Close']\n",
        "\n",
        "# --- THE FIX ---\n",
        "# Explicitly convert the resulting Series (or DataFrame) into a new DataFrame.\n",
        "data = pd.DataFrame(data_series)\n",
        "\n",
        "# Rename the column (which may be named 'SPY' or 'Close') to a consistent 'SPY'.\n",
        "data.columns = ['SPY']\n",
        "\n",
        "# 2. Feature Engineering\n",
        "# SPY returns are the ONLY feature now\n",
        "data['SPY_Returns'] = data['SPY'].pct_change() * 100\n",
        "\n",
        "# Drop the first row which contains NaN from the pct_change calculation\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# 3. Prepare Observation Data (X)\n",
        "# We use only SPY_Returns as the feature\n",
        "X = data[['SPY_Returns']].values\n",
        "\n",
        "print(f\"Data shape (Samples, Features): {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v02_maCyo6rt",
        "outputId": "5b99d6c0-f7b0-4f66-a1f5-cf518829cb8c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1865206708.py:12: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data_series = yf.download(TICKERS, start=START_DATE, end=END_DATE)['Close']\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape (Samples, Features): (956, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Initialize and Train the HMM\n",
        "# GaussianHMM is suitable for continuous data\n",
        "model = hmm.GaussianHMM(\n",
        "    n_components=N_COMPONENTS,\n",
        "    # Must change to 'diag' or 'spherical' since you have only 1 feature.\n",
        "    # 'full' expects a 2x2 or larger covariance matrix.\n",
        "    covariance_type=\"diag\",\n",
        "    n_iter=100\n",
        ")\n",
        "\n",
        "# Fit the model to the observation data\n",
        "print(\"\\nTraining HMM...\")\n",
        "model.fit(X)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 5. Predict the Hidden States\n",
        "# Predict the most likely sequence of hidden states (regimes)\n",
        "hidden_states = model.predict(X)\n",
        "\n",
        "# Add the states back to the original DataFrame for analysis\n",
        "data['Regime'] = hidden_states"
      ],
      "metadata": {
        "id": "BhdSxo0HsrtA",
        "outputId": "f4163de8-f158-45ff-86bd-35fa7b09fd1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training HMM...\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Parameter Initialization"
      ],
      "metadata": {
        "id": "Ret9G--JtjWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Apply Scaling ---\n",
        "# 3. Prepare and Scale Observation Data (X)\n",
        "X = data[['SPY_Returns']].values # Shape (N, 1)\n",
        "\n",
        "# Standard Scaling is essential for HMMs\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"Scaled Data shape (Samples, Features): {X_scaled.shape}\")\n",
        "\n",
        "# 4. Initialize and Train the HMM with Manual Parameters\n",
        "model = hmm.GaussianHMM(\n",
        "    n_components=N_COMPONENTS,\n",
        "    covariance_type=\"diag\",  # Correct for single feature\n",
        "    n_iter=200,             # Increased iterations\n",
        "    init_params=\"\"          # CRITICAL: Disable random initialization\n",
        ")\n",
        "\n",
        "# --- Manual Parameter Initialization to Force Regime Separation ---\n",
        "\n",
        "# Initialize Means (Shape: [3, 1])\n",
        "# We are forcing the model to start with clear directional expectations:\n",
        "model.means_ = np.array([\n",
        "    [ 1.0],  # Regime 0 (Bull): High positive mean on scaled data\n",
        "    [ 0.0],  # Regime 1 (Neutral): Mean near zero\n",
        "    [-1.0]   # Regime 2 (Bear): Low negative mean\n",
        "])\n",
        "\n",
        "# Initialize Covariances (Shape: [3, 1])\n",
        "# We are forcing the model to start with clear volatility expectations (variance = std_dev^2):\n",
        "model.covars_ = np.array([\n",
        "    [0.2],  # Regime 0 (Bull): LOW Volatility\n",
        "    [0.5],  # Regime 1 (Neutral): MEDIUM Volatility\n",
        "    [3.0]   # Regime 2 (Bear): HIGH Volatility\n",
        "])\n",
        "\n",
        "# Initialize Transition and Start Probabilities (Optional)\n",
        "model.transmat_ = np.full((N_COMPONENTS, N_COMPONENTS), 1.0 / N_COMPONENTS)\n",
        "model.startprob_ = np.full(N_COMPONENTS, 1.0 / N_COMPONENTS)\n",
        "\n",
        "\n",
        "# Fit the model to the SCALED observation data\n",
        "print(\"\\nTraining HMM with initial parameters...\")\n",
        "model.fit(X_scaled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 5. Predict the Hidden States\n",
        "hidden_states = model.predict(X_scaled)\n",
        "data['Regime'] = hidden_states\n",
        "\n"
      ],
      "metadata": {
        "id": "rfSmyAPFtiEV",
        "outputId": "ad67c190-13ee-4403-9323-c4df4950e4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Data shape (Samples, Features): (956, 1)\n",
            "\n",
            "Training HMM with initial parameters...\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\")\n",
        "# We select the Date (Index), SPY_Returns, and the predicted Regime\n",
        "daily_comparison = data[['SPY_Returns', 'Regime']].tail(30)\n",
        "print(daily_comparison)\n",
        "\n",
        "# Optional: To save this to a file for external analysis\n",
        "# daily_comparison.to_csv('daily_hmm_regime_vs_spy_return.csv')"
      ],
      "metadata": {
        "id": "P9zdE8HeupPt",
        "outputId": "f58d5603-ef70-42f6-831f-178ba3ff92c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\n",
            "            SPY_Returns  Regime\n",
            "Date                           \n",
            "2025-09-15     0.532388       0\n",
            "2025-09-16    -0.137687       0\n",
            "2025-09-17    -0.124236       0\n",
            "2025-09-18     0.467245       0\n",
            "2025-09-19     0.495284       0\n",
            "2025-09-22     0.473108       0\n",
            "2025-09-23    -0.544359       0\n",
            "2025-09-24    -0.318157       0\n",
            "2025-09-25    -0.461350       0\n",
            "2025-09-26     0.572908       0\n",
            "2025-09-29     0.281041       0\n",
            "2025-09-30     0.376688       0\n",
            "2025-10-01     0.340752       0\n",
            "2025-10-02     0.115186       0\n",
            "2025-10-03    -0.001487       0\n",
            "2025-10-06     0.358626       0\n",
            "2025-10-07    -0.370749       0\n",
            "2025-10-08     0.596304       0\n",
            "2025-10-09    -0.289702       0\n",
            "2025-10-10    -2.702776       1\n",
            "2025-10-13     1.534403       1\n",
            "2025-10-14    -0.122164       1\n",
            "2025-10-15     0.443955       1\n",
            "2025-10-16    -0.681024       1\n",
            "2025-10-17     0.567631       1\n",
            "2025-10-20     1.040048       1\n",
            "2025-10-21    -0.001491       1\n",
            "2025-10-22    -0.519893       1\n",
            "2025-10-23     0.592995       1\n",
            "2025-10-24     0.817255       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Analysis ---\n",
        "print(\"\\n### 📊 Regime Analysis (Mean and Volatility of SPY Returns) ###\")\n",
        "regime_stats = data.groupby('Regime')['SPY_Returns'].agg(\n",
        "    Count='size',\n",
        "    Mean='mean',\n",
        "    Std_Dev='std'\n",
        ")\n",
        "print(regime_stats.round(4))\n"
      ],
      "metadata": {
        "id": "KcVG8f63ufRR",
        "outputId": "dee9e960-49d4-440a-d8ff-6f17d54bd2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 📊 Regime Analysis (Mean and Volatility of SPY Returns) ###\n",
            "        Count    Mean  Std_Dev\n",
            "Regime                        \n",
            "0         337  0.1709   0.5154\n",
            "1         338  0.0392   0.9928\n",
            "2         281 -0.0867   1.7231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPY and VIX\n"
      ],
      "metadata": {
        "id": "GtsLARBHo7JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# Tickers\n",
        "TICKERS = ['SPY', '^VIX']\n",
        "# Date Range (Adjust as needed)\n",
        "START_DATE = '2015-01-01'\n",
        "END_DATE = '2025-10-01'\n",
        "# HMM Parameters\n",
        "N_COMPONENTS = 3 # Number of hidden states (regimes)\n",
        "\n",
        "# 1. Download Data\n",
        "data = yf.download(TICKERS, start=START_DATE, end=END_DATE)['Close']\n",
        "data.columns = ['SPY', 'VIX']\n",
        "\n",
        "# 2. Feature Engineering\n",
        "# SPY returns are key for direction/magnitude of movement\n",
        "data['SPY_Returns'] = data['SPY'].pct_change() * 100\n",
        "\n",
        "# VIX change is a good measure of increasing/decreasing fear/volatility\n",
        "data['VIX_Change'] = data['VIX'].pct_change() * 100\n",
        "\n",
        "# Drop the first row which contains NaN from the pct_change calculation\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# 3. Prepare Observation Data (X)\n",
        "# We combine the two features: SPY Returns and VIX Change\n",
        "# The HMM input (X) must be a 2D numpy array\n",
        "X = data[['SPY_Returns', 'VIX_Change']].values\n",
        "\n",
        "print(f\"Data shape (Samples, Features): {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djPMd-4geIAP",
        "outputId": "eeb863d9-f4ab-45cc-a0f6-0c7d5f36c639"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-696808036.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(TICKERS, start=START_DATE, end=END_DATE)['Close']\n",
            "\r[                       0%                       ]\r[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape (Samples, Features): (2701, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling"
      ],
      "metadata": {
        "id": "W1fj8mS1pZoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Prepare Observation Data (X) - BEFORE SCALING\n",
        "X = data[['SPY_Returns', 'VIX_Change']].values\n",
        "\n",
        "# --- NEW STEP: Apply Scaling ---\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler to the data and transform it\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# The HMM will now be trained on X_scaled"
      ],
      "metadata": {
        "id": "w-bEFaEUpY0k"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code for downloading data and creating 'data' DataFrame) ...\n",
        "\n",
        "# 3. Prepare Observation Data (X) - BEFORE SCALING\n",
        "X = data[['SPY_Returns', 'VIX_Change']].values\n",
        "\n",
        "# --- NEW STEP: Apply Scaling ---\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler to the data and transform it\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# The HMM will now be trained on X_scaled\n",
        "\n",
        "# 4. Initialize and Train the HMM using the SCALED data\n",
        "model = hmm.GaussianHMM(\n",
        "    n_components=N_COMPONENTS,\n",
        "    covariance_type=\"full\",\n",
        "    n_iter=100,\n",
        "    # Add n_init for better results (see section 2)\n",
        "    #n_init=10\n",
        ")\n",
        "\n",
        "# Fit the model to the SCALED observation data\n",
        "print(\"\\nTraining HMM on scaled data...\")\n",
        "model.fit(X_scaled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 5. Predict the Hidden States\n",
        "hidden_states = model.predict(X_scaled) # Predict using the scaled data\n",
        "data['Regime'] = hidden_states # Add states to the original data frame\n",
        "\n",
        "# Now run your analysis again (Regime Analysis, Daily Comparison)\n",
        "# The output should show multiple regimes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph32kAJime1O",
        "outputId": "938bf414-b80b-4244-e115-50fa6187e0d0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training HMM on scaled data...\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best_hmm(X_scaled, n_components, n_attempts=10, n_iter=100):\n",
        "    \"\"\"\n",
        "    Trains the GaussianHMM multiple times and returns the model\n",
        "    with the highest log-likelihood score.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from hmmlearn import hmm\n",
        "\n",
        "    best_score = -np.inf\n",
        "    best_model = None\n",
        "\n",
        "    print(f\"Attempting HMM fit {n_attempts} times...\")\n",
        "    for i in range(n_attempts):\n",
        "        # Initialize a new model for each attempt\n",
        "        current_model = hmm.GaussianHMM(\n",
        "            n_components=n_components,\n",
        "            covariance_type=\"full\",\n",
        "            n_iter=n_iter\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Fit the model to the scaled data\n",
        "            current_model.fit(X_scaled)\n",
        "            current_score = current_model.score(X_scaled)\n",
        "\n",
        "            if current_score > best_score:\n",
        "                best_score = current_score\n",
        "                best_model = current_model\n",
        "                # print(f\"  Attempt {i+1}: New Best Score = {best_score:.2f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle potential training failures (e.g., singular matrix)\n",
        "            # print(f\"  Attempt {i+1}: Failed with error: {e}\")\n",
        "            continue\n",
        "\n",
        "    if best_model is None:\n",
        "        raise RuntimeError(\"HMM training failed for all attempts. Check data for issues.\")\n",
        "\n",
        "    print(f\"Training complete. Best score: {best_score:.2f}\")\n",
        "    return best_model\n",
        "\n",
        "# --- REPLACE YOUR ORIGINAL TRAINING BLOCK WITH THIS ---\n",
        "# X_scaled must be available from your previous scaling step\n",
        "model = train_best_hmm(X_scaled, n_components=N_COMPONENTS, n_attempts=20, n_iter=200)\n",
        "\n",
        "# 5. Predict the Hidden States using the best model\n",
        "hidden_states = model.predict(X_scaled)\n",
        "data['Regime'] = hidden_states\n",
        "# Now run your regime analysis and daily comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELxElHe9nZSG",
        "outputId": "d9f4f793-ac27-4b35-e85b-0014fff634d1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting HMM fit 20 times...\n",
            "Training complete. Best score: -5154.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Assuming your 'data' DataFrame looks like this after training:\n",
        "# data['SPY_Returns'] = data['SPY'].pct_change() * 100\n",
        "# data['Regime'] = model.predict(X)\n",
        "\n",
        "print(\"### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\")\n",
        "# We select the Date (Index), SPY_Returns, and the predicted Regime\n",
        "daily_comparison = data[['SPY_Returns', 'VIX_Change', 'Regime']].tail(30)\n",
        "print(daily_comparison)\n",
        "\n",
        "# Optional: To save this to a file for external analysis\n",
        "# daily_comparison.to_csv('daily_hmm_regime_vs_spy_return.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDLUzHqdjgtx",
        "outputId": "b9126e44-3871-4027-eda9-9edbe69117ba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\n",
            "            SPY_Returns  VIX_Change  Regime\n",
            "Date                                       \n",
            "2025-08-19    -0.542514    3.869246       1\n",
            "2025-08-20    -0.265706    0.770712       1\n",
            "2025-08-21    -0.401184    5.799878       1\n",
            "2025-08-22     1.535680  -14.337350       1\n",
            "2025-08-25    -0.440109    4.008437       1\n",
            "2025-08-26     0.418705   -1.149426       1\n",
            "2025-08-27     0.227851    1.573191       1\n",
            "2025-08-28     0.354138   -2.828283       1\n",
            "2025-08-29    -0.596368    6.444902       1\n",
            "2025-09-02    -0.741028   11.783857       1\n",
            "2025-09-03     0.541956   -4.775770       1\n",
            "2025-09-04     0.835739   -6.422019       1\n",
            "2025-09-05    -0.289625   -0.784313       1\n",
            "2025-09-08     0.245663   -0.461137       1\n",
            "2025-09-09     0.231185   -0.463267       1\n",
            "2025-09-10     0.289086    2.061173       1\n",
            "2025-09-11     0.831023   -4.169383       1\n",
            "2025-09-12    -0.033458    0.339906       1\n",
            "2025-09-15     0.532388    6.300809       1\n",
            "2025-09-16    -0.137687    4.270242       1\n",
            "2025-09-17    -0.124236   -3.911982       1\n",
            "2025-09-18     0.467245   -0.127229       1\n",
            "2025-09-19     0.495284   -1.592357       1\n",
            "2025-09-22     0.473108    4.207123       1\n",
            "2025-09-23    -0.544359    3.354031       1\n",
            "2025-09-24    -0.318157   -2.764418       1\n",
            "2025-09-25    -0.461350    3.461060       1\n",
            "2025-09-26     0.572908   -8.661887       1\n",
            "2025-09-29     0.281041    5.428390       1\n",
            "2025-09-30     0.376688    0.992555       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Analyze the Regimes\n",
        "print(\"\\n--- Regime Analysis (Mean of Features) ---\")\n",
        "regime_analysis = data.groupby('Regime')[['SPY_Returns', 'VIX_Change']].mean()\n",
        "print(regime_analysis)\n",
        "\n",
        "# 7. Directional Prediction Insight\n",
        "# Identify the most \"Bullish\" and \"Bearish\" regimes\n",
        "# Sort by SPY_Returns to find the order\n",
        "sorted_regimes = regime_analysis.sort_values(by='SPY_Returns', ascending=False)\n",
        "\n",
        "print(\"\\n### 📊 Comprehensive Regime Analysis (Count, Mean, and Volatility) ###\")\n",
        "\n",
        "# 1. Group the data by the 'Regime' column\n",
        "regime_groups = data.groupby('Regime')\n",
        "\n",
        "# 2. Calculate Count, Mean, and Standard Deviation for SPY_Returns and VIX_Change\n",
        "regime_stats = regime_groups[['SPY_Returns', 'VIX_Change']].agg(\n",
        "    # Count of samples (days) in the regime\n",
        "    Count=('SPY_Returns', 'size'),\n",
        "    # Mean of SPY Returns for directional insight\n",
        "    SPY_Returns_Mean=('SPY_Returns', 'mean'),\n",
        "    # Standard Deviation of SPY Returns for volatility insight\n",
        "    SPY_Returns_Std_Dev=('SPY_Returns', 'std'),\n",
        "    # Mean of VIX Change (for confirming volatility behavior)\n",
        "    VIX_Change_Mean=('VIX_Change', 'mean')\n",
        ")\n",
        "\n",
        "# 3. Print the resulting statistics\n",
        "print(regime_stats.round(4))\n",
        "\n",
        "print(\"\\n--- Directional Insight ---\")\n",
        "print(f\"The most **Bullish Regime** (highest positive SPY Return) is Regime **{sorted_regimes.index[0]}**\")\n",
        "print(f\"The most **Bearish Regime** (highest negative SPY Return) is Regime **{sorted_regimes.index[-1]}**\")\n",
        "\n",
        "# 8. Making a Forward Prediction (The core step)\n",
        "# To predict the next day's regime, you use the HMM's transition matrix and the current state.\n",
        "# Let's get the state of the *last* day in the dataset\n",
        "current_regime = data['Regime'].iloc[-1]\n",
        "transition_matrix = model.transmat_\n",
        "\n",
        "# Get the transition probabilities from the current regime to all others\n",
        "next_state_probs = transition_matrix[current_regime]\n",
        "\n",
        "print(\"\\n--- Next Day Regime Probability ---\")\n",
        "print(f\"Current Regime (Today's Close): **Regime {current_regime}**\")\n",
        "print(\"Probability of transitioning to each regime tomorrow:\")\n",
        "for i in range(N_COMPONENTS):\n",
        "    # Lookup the mean SPY return for this predicted state\n",
        "    mean_return = regime_analysis.loc[i, 'SPY_Returns']\n",
        "    print(f\"  - Regime {i}: {next_state_probs[i]:.2f} (Avg SPY Return: {mean_return:.2f}%)\")\n",
        "\n",
        "# The regime with the highest probability is your prediction\n",
        "predicted_next_regime = np.argmax(next_state_probs)\n",
        "predicted_return = regime_analysis.loc[predicted_next_regime, 'SPY_Returns']\n",
        "\n",
        "print(f\"\\n**Prediction:** The most likely regime for tomorrow is **Regime {predicted_next_regime}** with an expected average SPY return of **{predicted_return:.2f}%**.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWcRIh1MgRZD",
        "outputId": "fa6c8fad-bb42-4e31-c510-815a953282dd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Regime Analysis (Mean of Features) ---\n",
            "        SPY_Returns  VIX_Change\n",
            "Regime                         \n",
            "0          0.065975   -0.464485\n",
            "1          0.110717   -0.114986\n",
            "2         -1.047688   14.619184\n",
            "\n",
            "### 📊 Comprehensive Regime Analysis (Count, Mean, and Volatility) ###\n",
            "        Count  SPY_Returns_Mean  SPY_Returns_Std_Dev  VIX_Change_Mean\n",
            "Regime                                                               \n",
            "0         697            0.0660               1.3927          -0.4645\n",
            "1        1905            0.1107               0.6316          -0.1150\n",
            "2          99           -1.0477               3.4944          14.6192\n",
            "\n",
            "--- Directional Insight ---\n",
            "The most **Bullish Regime** (highest positive SPY Return) is Regime **1**\n",
            "The most **Bearish Regime** (highest negative SPY Return) is Regime **2**\n",
            "\n",
            "--- Next Day Regime Probability ---\n",
            "Current Regime (Today's Close): **Regime 1**\n",
            "Probability of transitioning to each regime tomorrow:\n",
            "  - Regime 0: 0.00 (Avg SPY Return: 0.07%)\n",
            "  - Regime 1: 0.97 (Avg SPY Return: 0.11%)\n",
            "  - Regime 2: 0.03 (Avg SPY Return: -1.05%)\n",
            "\n",
            "**Prediction:** The most likely regime for tomorrow is **Regime 1** with an expected average SPY return of **0.11%**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Initialize the Variance Manually\n",
        "---\n"
      ],
      "metadata": {
        "id": "ALwiJlcOpD7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hmm_with_initial_volatility(X_scaled, n_components, stable_volatility=0.2, crash_volatility=2.0):\n",
        "    \"\"\"Initializes HMM with distinct volatility parameters to force separation.\"\"\"\n",
        "    from hmmlearn import hmm\n",
        "    import numpy as np\n",
        "\n",
        "    # Initialize the model, but tell it NOT to randomize parameters (init_params=\"\")\n",
        "    model = hmm.GaussianHMM(\n",
        "        n_components=n_components,\n",
        "        covariance_type=\"full\",\n",
        "        n_iter=200,\n",
        "        init_params=\"\" # Important: Prevents default random initialization\n",
        "    )\n",
        "\n",
        "    # 1. Initialize Covariance Matrix (Variance)\n",
        "    # This matrix is [n_components, n_features, n_features]\n",
        "    # We assume Regime 0 (Bull) is low vol, Regime 2 (Bear) is high vol.\n",
        "    covars_init = np.zeros((n_components, X_scaled.shape[1], X_scaled.shape[1]))\n",
        "\n",
        "    # Set initial low variance for the 'stable' regimes (e.g., Regime 0 and 1)\n",
        "    # We use stable_volatility for the diagonal of the covariance matrix\n",
        "    # (since the data is scaled, 0.2 and 2.0 are relative values)\n",
        "    stable_cov_val = stable_volatility ** 2\n",
        "    for i in range(n_components - 1): # Apply to regimes 0 and 1\n",
        "        np.fill_diagonal(covars_init[i], stable_cov_val)\n",
        "\n",
        "    # Set initial high variance for the 'crisis' regime (e.g., Regime 2)\n",
        "    crash_cov_val = crash_volatility ** 2\n",
        "    np.fill_diagonal(covars_init[n_components - 1], crash_cov_val)\n",
        "\n",
        "    model.covars_ = covars_init\n",
        "\n",
        "    # 2. Initialize Transition and Start Probabilities (optional, but good practice)\n",
        "    # You can leave these random, but explicitly setting them is safer.\n",
        "    model.transmat_ = np.full((n_components, n_components), 1.0 / n_components)\n",
        "    model.startprob_ = np.full(n_components, 1.0 / n_components)\n",
        "\n",
        "    # 3. Fit the model\n",
        "    # Note: Mean (means_) is still randomly initialized and learned in the fit process\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- RERUN YOUR TRAINING WITH THE NEW FUNCTION ---\n",
        "# You can try a new set of volatile starting values if the default 0.2/2.0 fails\n",
        "model = train_hmm_with_initial_volatility(\n",
        "    X_scaled,\n",
        "    n_components=N_COMPONENTS,\n",
        "    stable_volatility=0.2,\n",
        "    crash_volatility=2.0\n",
        ")\n",
        "\n",
        "# Predict and check results...\n",
        "hidden_states = model.predict(X_scaled)\n",
        "data['Regime'] = hidden_states"
      ],
      "metadata": {
        "id": "sCt2SJ6LpItJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Assuming your 'data' DataFrame looks like this after training:\n",
        "# data['SPY_Returns'] = data['SPY'].pct_change() * 100\n",
        "# data['Regime'] = model.predict(X)\n",
        "\n",
        "print(\"### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\")\n",
        "# We select the Date (Index), SPY_Returns, and the predicted Regime\n",
        "daily_comparison = data[['SPY_Returns', 'VIX_Change', 'Regime']].tail(30)\n",
        "print(daily_comparison)\n",
        "\n",
        "# Optional: To save this to a file for external analysis\n",
        "# daily_comparison.to_csv('daily_hmm_regime_vs_spy_return.csv')"
      ],
      "metadata": {
        "id": "yk7qItD4qGlS",
        "outputId": "492daff6-a412-468a-8a7e-87381d17ea20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Daily Regime vs. SPY Return Comparison (Last 30 Days) ###\n",
            "            SPY_Returns  VIX_Change  Regime\n",
            "Date                                       \n",
            "2025-08-19    -0.542514    3.869246       0\n",
            "2025-08-20    -0.265706    0.770712       0\n",
            "2025-08-21    -0.401184    5.799878       0\n",
            "2025-08-22     1.535680  -14.337350       0\n",
            "2025-08-25    -0.440109    4.008437       0\n",
            "2025-08-26     0.418705   -1.149426       0\n",
            "2025-08-27     0.227851    1.573191       0\n",
            "2025-08-28     0.354138   -2.828283       0\n",
            "2025-08-29    -0.596368    6.444902       0\n",
            "2025-09-02    -0.741028   11.783857       0\n",
            "2025-09-03     0.541956   -4.775770       0\n",
            "2025-09-04     0.835739   -6.422019       0\n",
            "2025-09-05    -0.289625   -0.784313       0\n",
            "2025-09-08     0.245663   -0.461137       0\n",
            "2025-09-09     0.231185   -0.463267       0\n",
            "2025-09-10     0.289086    2.061173       0\n",
            "2025-09-11     0.831023   -4.169383       0\n",
            "2025-09-12    -0.033458    0.339906       0\n",
            "2025-09-15     0.532388    6.300809       0\n",
            "2025-09-16    -0.137687    4.270242       0\n",
            "2025-09-17    -0.124236   -3.911982       0\n",
            "2025-09-18     0.467245   -0.127229       0\n",
            "2025-09-19     0.495284   -1.592357       0\n",
            "2025-09-22     0.473108    4.207123       0\n",
            "2025-09-23    -0.544359    3.354031       0\n",
            "2025-09-24    -0.318157   -2.764418       0\n",
            "2025-09-25    -0.461350    3.461060       0\n",
            "2025-09-26     0.572908   -8.661887       0\n",
            "2025-09-29     0.281041    5.428390       0\n",
            "2025-09-30     0.376688    0.992555       0\n"
          ]
        }
      ]
    }
  ]
}